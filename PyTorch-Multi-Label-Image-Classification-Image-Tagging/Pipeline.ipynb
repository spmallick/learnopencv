{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install numpy scikit-image scipy scikit-learn matplotlib tqdm tensorflow torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import printoptions\n",
    "import requests\n",
    "import tarfile\n",
    "import random\n",
    "import json\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds to make experiments reproducible\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the .tar.gz archive from this(https://github.com/thuml/HashNet/tree/master/pytorch#datasets) \n",
    "# github repository to speed up image loading(instead of loading it from Flickr).\n",
    "# Let's download and extract it.\n",
    "img_folder = 'images'\n",
    "if not os.path.exists(img_folder):\n",
    "    def download_file_from_google_drive(id, destination):\n",
    "        def get_confirm_token(response):\n",
    "            for key, value in response.cookies.items():\n",
    "                if key.startswith('download_warning'):\n",
    "                    return value\n",
    "            return None\n",
    "\n",
    "        def save_response_content(response, destination):\n",
    "            CHUNK_SIZE = 32768\n",
    "            with open(destination, \"wb\") as f:\n",
    "                for chunk in tqdm(response.iter_content(CHUNK_SIZE), desc='Downloading'):\n",
    "                    if chunk:  # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "        session = requests.Session()\n",
    "        response = session.get(URL, params={'id': id}, stream=True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = {'id': id, 'confirm': token}\n",
    "            response = session.get(URL, params=params, stream=True)\n",
    "        save_response_content(response, destination)\n",
    "\n",
    "    file_id = '0B7IzDz-4yH_HMFdiSE44R1lselE'\n",
    "    path_to_tar_file = str(time.time()) + '.tar.gz'\n",
    "    download_file_from_google_drive(file_id, path_to_tar_file)\n",
    "    print('Extraction')\n",
    "    with tarfile.open(path_to_tar_file) as tar_ref:\n",
    "        tar_ref.extractall(os.path.dirname(img_folder))\n",
    "    os.remove(path_to_tar_file)\n",
    "# Also, copy our pre-processed annotations to the dataset folder. \n",
    "# Note: you can find script for generating such annotations in attachments\n",
    "copyfile('nus_wide/small_test.json', os.path.join(img_folder, 'small_test.json'))\n",
    "copyfile('nus_wide/small_train.json', os.path.join(img_folder, 'small_train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dataloader and label binarization, that is converting test labels into binary arrays of length 27 (number of classes) with 1 in places of applicable labels).\n",
    "class NusDataset(Dataset):\n",
    "    def __init__(self, data_path, anno_path, transforms):\n",
    "        self.transforms = transforms\n",
    "        with open(anno_path) as fp:\n",
    "            json_data = json.load(fp)\n",
    "        samples = json_data['samples']\n",
    "        self.classes = json_data['labels']\n",
    "\n",
    "        self.imgs = []\n",
    "        self.annos = []\n",
    "        self.data_path = data_path\n",
    "        print('loading', anno_path)\n",
    "        for sample in samples:\n",
    "            self.imgs.append(sample['image_name'])\n",
    "            self.annos.append(sample['image_labels'])\n",
    "        for item_id in range(len(self.annos)):\n",
    "            item = self.annos[item_id]\n",
    "            vector = [cls in item for cls in self.classes]\n",
    "            self.annos[item_id] = np.array(vector, dtype=float)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anno = self.annos[item]\n",
    "        img_path = os.path.join(self.data_path, self.imgs[item])\n",
    "        img = Image.open(img_path)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, anno\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the data we have. To do it we need to load the dataset without augmentations.\n",
    "dataset_val = NusDataset(img_folder, os.path.join(img_folder, 'small_test.json'), None)\n",
    "dataset_train = NusDataset(img_folder, os.path.join(img_folder, 'small_train.json'), None)\n",
    "\n",
    "# A simple function for visualization.\n",
    "def show_sample(img, binary_img_labels):\n",
    "    # Convert the binary labels back to the text representation.    \n",
    "    img_labels = np.array(dataset_val.classes)[np.argwhere(binary_img_labels > 0)[:, 0]]\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"{}\".format(', '.join(img_labels)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for sample_id in range(5):\n",
    "    show_sample(*dataset_val[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label distribution for the entire dataset (train + test)\n",
    "samples = dataset_val.annos + dataset_train.annos\n",
    "samples = np.array(samples)\n",
    "with printoptions(precision=3, suppress=True):\n",
    "    class_counts = np.sum(samples, axis=0)\n",
    "    # Sort labels according to their frequency in the dataset.\n",
    "    sorted_ids = np.array([i[0] for i in sorted(enumerate(class_counts), key=lambda x: x[1])], dtype=int)\n",
    "    print('Label distribution (count, class name):', list(zip(class_counts[sorted_ids].astype(int), np.array(dataset_val.classes)[sorted_ids])))\n",
    "    plt.barh(range(len(dataset_val.classes)), width=class_counts[sorted_ids])\n",
    "    plt.yticks(range(len(dataset_val.classes)), np.array(dataset_val.classes)[sorted_ids])\n",
    "    plt.gca().margins(y=0)\n",
    "    plt.grid()\n",
    "    plt.title('Label distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the torchvision's implementation of ResNeXt, but add FC layer for a different number of classes (27) and a Sigmoid instead of a default Softmax.\n",
    "class Resnext50(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnext50_32x4d(pretrained=True)\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    pred = np.array(pred > threshold, dtype=float)\n",
    "    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the training parameters.\n",
    "num_workers = 8 # Number of CPU processes for data preprocessing\n",
    "lr = 1e-4 # Learning rate\n",
    "batch_size = 32\n",
    "save_freq = 1 # Save checkpoint frequency (epochs)\n",
    "test_freq = 200 # Test model frequency (iterations)\n",
    "max_epoch_number = 35 # Number of epochs for training \n",
    "# Note: on the small subset of data overfitting happens after 30-35 epochs\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# Save path for checkpoints\n",
    "save_path = 'chekpoints/'\n",
    "# Save path for logs\n",
    "logdir = 'logs/'\n",
    "\n",
    "# Run tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an auxiliary function for checkpoint saving.\n",
    "def checkpoint_save(model, save_path, epoch):\n",
    "    f = os.path.join(save_path, 'checkpoint-{:06d}.pth'.format(epoch))\n",
    "    if 'module' in dir(model):\n",
    "        torch.save(model.module.state_dict(), f)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f)\n",
    "    print('saved checkpoint:', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocessing\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "print(tuple(np.array(np.array(mean)*255).tolist()))\n",
    "\n",
    "# Train preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(0.5, 1.5),\n",
    "                            shear=None, resample=False, \n",
    "                            fillcolor=tuple(np.array(np.array(mean)*255).astype(int).tolist())),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataloaders for training.\n",
    "test_annotations = os.path.join(img_folder, 'small_test.json')\n",
    "train_annotations = os.path.join(img_folder, 'small_train.json')\n",
    "\n",
    "test_dataset = NusDataset(img_folder, test_annotations, val_transform)\n",
    "train_dataset = NusDataset(img_folder, train_annotations, train_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True,\n",
    "                              drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "num_train_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
    "\n",
    "# Initialize the model\n",
    "model = Resnext50(len(train_dataset.classes))\n",
    "# Switch model to the training mode and move it to GPU.\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# If more than one GPU is available we can use both to speed up the training.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "# Tensoboard logger\n",
    "logger = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "epoch = 0\n",
    "iteration = 0\n",
    "while True:\n",
    "    batch_losses = []\n",
    "    for imgs, targets in train_dataloader:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(imgs)\n",
    "        loss = criterion(model_result, targets.type(torch.float))\n",
    "\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logger.add_scalar('train_loss', batch_loss_value, iteration)\n",
    "        batch_losses.append(batch_loss_value)\n",
    "        with torch.no_grad():\n",
    "            result = calculate_metrics(model_result.cpu().numpy(), targets.cpu().numpy())\n",
    "            for metric in result:\n",
    "                logger.add_scalar('train/' + metric, result[metric], iteration)\n",
    "\n",
    "        if iteration % test_freq == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                model_result = []\n",
    "                targets = []\n",
    "                for imgs, batch_targets in test_dataloader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    model_batch_result = model(imgs)\n",
    "                    model_result.extend(model_batch_result.cpu().numpy())\n",
    "                    targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "            result = calculate_metrics(np.array(model_result), np.array(targets))\n",
    "            for metric in result:\n",
    "                logger.add_scalar('test/' + metric, result[metric], iteration)\n",
    "            print(\"epoch:{:2d} iter:{:3d} test: \"\n",
    "                  \"micro f1: {:.3f} \"\n",
    "                  \"macro f1: {:.3f} \"\n",
    "                  \"samples f1: {:.3f}\".format(epoch, iteration,\n",
    "                                              result['micro/f1'],\n",
    "                                              result['macro/f1'],\n",
    "                                              result['samples/f1']))\n",
    "\n",
    "            model.train()\n",
    "        iteration += 1\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    print(\"epoch:{:2d} iter:{:3d} train: loss:{:.3f}\".format(epoch, iteration, loss_value))\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_save(model, save_path, epoch)\n",
    "    epoch += 1\n",
    "    if max_epoch_number < epoch:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run inference on the test data\n",
    "model.eval()\n",
    "for sample_id in [1,2,3,4,6]:\n",
    "    test_img, test_labels = test_dataset[sample_id]\n",
    "    test_img_path = os.path.join(img_folder, test_dataset.imgs[sample_id])\n",
    "    with torch.no_grad():\n",
    "        raw_pred = model(test_img.unsqueeze(0)).cpu().numpy()[0]\n",
    "        raw_pred = np.array(raw_pred > 0.5, dtype=float)\n",
    "\n",
    "    predicted_labels = np.array(dataset_val.classes)[np.argwhere(raw_pred > 0)[:, 0]]\n",
    "    if not len(predicted_labels):\n",
    "        predicted_labels = ['no predictions']\n",
    "    img_labels = np.array(dataset_val.classes)[np.argwhere(test_labels > 0)[:, 0]]\n",
    "    plt.imshow(Image.open(test_img_path))\n",
    "    plt.title(\"Predicted labels: {} \\nGT labels: {}\".format(', '.join(predicted_labels), ', '.join(img_labels)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog_venv",
   "language": "python",
   "name": "blog_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
