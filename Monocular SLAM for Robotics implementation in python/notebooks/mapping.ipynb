{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import time\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KNN Implementation \n",
    "\"\"\"\n",
    "\n",
    "def euclidianDistance(des1, des2):\n",
    "    distance = 0\n",
    "    \n",
    "    for x in range(len(des1)):\n",
    "        distance += pow(des1[x] - des2[x], 2)\n",
    "        \n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def EUBetter(des1,des2,distances,iteration):\n",
    "    des1 = np.array(des1)\n",
    "    des2 = np.array(des2)\n",
    "    \n",
    "    distance = des1 - des2\n",
    "    distance = np.power(distance,2)\n",
    "    distance = np.sum(distance, axis = 1)\n",
    "    distance = np.sqrt(distance)\n",
    "    distance_indices = np.argsort(distance)\n",
    "    \n",
    "    k_match = []\n",
    "    for i in range(2):\n",
    "        k_match.append(cv2.DMatch(iteration,distance_indices[i],distance[distance_indices[i]]))\n",
    "    return k_match\n",
    "    \n",
    "def KNNMatch(des1,des2, k = 2): #query , #train\n",
    "    matches = []\n",
    "    for i in range(len(des1)):\n",
    "        distances = []\n",
    "        \n",
    "        t1 = time.time()\n",
    "        k_match = EUBetter(des1[i], des2, distances,i)\n",
    "        matches.append(k_match) \n",
    "                               \n",
    "    return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "class SFMSolver(object):\n",
    "\n",
    "    def __init__(self, img_pattern, intrinsic, output_dir, downscale=1):\n",
    "        \"\"\"\n",
    "        img_pattern: regex pattern used by glob to read the files\n",
    "        instrinsic:\n",
    "        \"\"\"\n",
    "        self.img_pattern = img_pattern\n",
    "        self.K_orig = self.intrinsic_orig = intrinsic.copy()\n",
    "        self.output_dir = output_dir\n",
    "        self.downscale = downscale\n",
    "        self.rescale_intrinsic()\n",
    "\n",
    "    def rescale_intrinsic(self):\n",
    "        \"\"\"\n",
    "        if we downscale the image, the intrinsic matrix\n",
    "        also needs to be changed.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        # scale focal length and principal points wrt image resizeing\n",
    "        if self.downscale > 1:\n",
    "            self.K = self.K_orig.copy()\n",
    "            self.K[0, 0] /= float(self.downscale)\n",
    "            self.K[1, 1] /= float(self.downscale)\n",
    "            self.K[0, 2] /= float(self.downscale)\n",
    "            self.K[1, 2] /= float(self.downscale)\n",
    "            self.intrinsic = self.K\n",
    "        else:\n",
    "            self.K = self.intrinsic = self.K_orig.copy()\n",
    "        elapsed = time.time() - start\n",
    "       \n",
    "              \n",
    "    def load_images(self):\n",
    "        \"\"\"\n",
    "        Loads a set of images to self.imgs list\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.img_paths = sorted(glob(self.img_pattern))\n",
    "        self.imgs = []\n",
    "        for idx, this_path in enumerate(self.img_paths):\n",
    "            try:\n",
    "                this_img = cv2.imread(this_path)\n",
    "                if self.downscale > 1:\n",
    "                    this_img = cv2.resize(this_img, (0, 0),\n",
    "                                          fx=1/float(self.downscale),\n",
    "                                          fy=1/float(self.downscale),\n",
    "                                          interpolation=cv2.INTER_LINEAR)\n",
    "            except Exception as e:\n",
    "                print(\"error loading img: %s\" % (this_path))\n",
    "            if this_img is not None:\n",
    "                self.imgs.append(this_img)\n",
    "                print(\"loaded img %d size=(%d,%d): %s\" %\n",
    "                      (idx, this_img.shape[0], this_img.shape[1], this_path))\n",
    "        #print(\"loaded %d images\" % (len(self.imgs)))\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def visualize_matches(self, img1, img2,\n",
    "                          kp1, kp2, good,\n",
    "                          mask=None, save_path=None):\n",
    "        start = time.time()\n",
    "        draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                           singlePointColor=None,\n",
    "                           flags=2)\n",
    "        if mask is not None:\n",
    "            if not isinstance(mask, list):\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "            else:\n",
    "                matchesMask = mask\n",
    "            draw_params['matchesMask'] = matchesMask\n",
    "        img_matches = cv2.drawMatches(\n",
    "            img1, kp1, img2, kp2, good, None, **draw_params)\n",
    "        cv2.imwrite(save_path, img_matches)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def drawlines(self, img1, img2, lines, pts1, pts2, line_num=None):\n",
    "        \"\"\"\n",
    "        Draw line connecting points in two images.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        if img1.ndim == 2:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "            r, c = img1.shape\n",
    "        else:  # 3\n",
    "            r, c, _ = img1.shape\n",
    "        if line_num is not None:\n",
    "            draw_list = np.random.choice(\n",
    "                pts1.shape[0], line_num, replace=False)\n",
    "        else:\n",
    "            draw_list = np.arange(pts1.shape[0])\n",
    "        for idx, (r, pt1, pt2) in enumerate(zip(lines, pts1, pts2)):\n",
    "            if idx not in list(draw_list):\n",
    "                continue\n",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "            x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "            x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "\n",
    "            pt1_int = (int(tuple(pt1.ravel())[0]), int(tuple(pt1.ravel())[1]))\n",
    "            pt2_int = (int(tuple(pt2.ravel())[0]), int(tuple(pt2.ravel())[1]))\n",
    "            \n",
    "            img1 = cv2.line(img1, (int(x0), int(y0)), (int(x1), int(y1)), color, 1)\n",
    "            img1 = cv2.circle(img1, pt1_int, 5, color, -1)\n",
    "            img2 = cv2.circle(img2, pt2_int, 5, color, -1)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return img1, img2\n",
    "\n",
    "    def visualize_epipolar_lines(self, img1, img2, p1, p2, E, save_path):\n",
    "        start = time.time()\n",
    "        # get fundamental matrix\n",
    "        F, mask_fdm = cv2.findFundamentalMat(p1, p2, cv2.RANSAC)\n",
    "        p1_selected = p1[mask_fdm.ravel() == 1]\n",
    "        p2_selected = p2[mask_fdm.ravel() == 1]\n",
    "\n",
    "        # draw lines\n",
    "        lines1 = cv2.computeCorrespondEpilines(\n",
    "            p2_selected.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "        img5, _ = self.drawlines(\n",
    "            img1, img2, lines1, p1_selected, p2_selected, 100)\n",
    "\n",
    "        lines2 = cv2.computeCorrespondEpilines(\n",
    "            p1_selected.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "        img3, _ = self.drawlines(\n",
    "            img2, img1, lines2, p2_selected, p1_selected, 100)\n",
    "        canvas = np.concatenate((img5, img3), axis=1)\n",
    "        cv2.imwrite(save_path, canvas)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "\n",
    "    def write_simple_obj(self, mesh_v, mesh_f, filepath, verbose=False):\n",
    "        \"\"\"\n",
    "        Saves 3d points which can be read in meshlab\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        with open(filepath, 'w') as fp:\n",
    "            for v in mesh_v:\n",
    "                fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n",
    "            if mesh_f is not None:\n",
    "                for f in mesh_f+1:  # Faces are 1-based, not 0-based in obj files\n",
    "                    fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n",
    "        if verbose:\n",
    "            print('mesh saved to: ', filepath)\n",
    "        elapsed = time.time() - start \n",
    "\n",
    "    # def write_simple_pcd(self, mesh_v, mesh_f, filepath, verbose=False):\n",
    "\n",
    "    \n",
    "    def write_simple_pcd(self, point_3d, filepath, verbose=False):\n",
    "        \"\"\"\n",
    "        Saves 3d points which can be read in meshlab\n",
    "        \"\"\"\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_3d)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.zeros_like(point_3d))\n",
    "        \n",
    "\n",
    "        o3d.io.write_point_cloud(filepath, pcd)\n",
    "        \n",
    "    def detect_and_match_feature(self, img1, img2):\n",
    "        start = time.time()\n",
    "        sift = cv2.xfeatures2d.SIFT_create() # Create SIFT object\n",
    "        kp1,des1 = sift.detectAndCompute(img1,None) # Detect keypoints and find descriptiors of first image\n",
    "        elapsed1 = time.time() - start\n",
    "        start1 = time.time()\n",
    "        kp2,des2 = sift.detectAndCompute(img2,None) # Detect keypoints and find descriptiors of second image\n",
    "        print(np.shape(des1))\n",
    "        print(np.shape(des2))\n",
    "        \n",
    "        \n",
    "        start2 = time.time()\n",
    "        start4 = time.time()\n",
    "        matches = KNNMatch(des1,des2,k=2)\n",
    "        \n",
    "        elapsed2 = time.time() - start4\n",
    "        print(\"Time for detect and match feature description {}\".format(elapsed2))\n",
    "        \n",
    "        matches_good = []\n",
    "        \n",
    "        start3 = time.time()\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7 * n.distance: # Perform ratio test to select good feature matches. Here 0.7 is the threshold. Can change between 0.5 - 1\n",
    "                matches_good.append(m)\n",
    "        elapsed3 = time.time() - start3\n",
    "       \n",
    "        \n",
    "        p1 = np.float32([kp1[m.queryIdx].pt for m in matches_good]).reshape(-1,1,2) # Find those keypoints with descriptors that pass ratio test\n",
    "        p2 = np.float32([kp2[m.trainIdx].pt for m in matches_good]).reshape(-1,1,2) # Find those keypoints with descriptors that pass ratio test\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return p1, p2, matches_good, kp1, kp2\n",
    "\n",
    "    def compute_essential(self, p1, p2):\n",
    "        start = time.time()\n",
    "        E, mask = cv2.findEssentialMat(p1, p2, self.intrinsic) # Find essential matrix\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return E, mask\n",
    "\n",
    "    def compute_pose(self, p1, p2, E):\n",
    "        start = time.time()\n",
    "        retval, R, trans, mask = cv2.recoverPose(E, p1, p2, self.intrinsic)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return R, trans\n",
    "\n",
    "    def triangulate(self, p1, p2, R, trans, mask):\n",
    "        start = time.time()\n",
    "        matchesMask = mask.ravel().tolist() # Use mask to remove outliers\n",
    "        p1 = p1[np.asarray(matchesMask)==1,:,:]\n",
    "        p2 = p2[np.asarray(matchesMask)==1,:,:]\n",
    "\n",
    "        P1 = cv2.undistortPoints(p1, self.intrinsic,None) # Convert image coordinates to normalized coordinates for first image\n",
    "        P2 = cv2.undistortPoints(p2, self.intrinsic,None) # Convert image coordinates to normalized coordinates for second image\n",
    "\n",
    "        I = np.identity(3) # Rotation of first camera. Identity as origin is at first camera\n",
    "        z = np.zeros((3,1)) #  Translation of first camera. Zero as origin is at first camera\n",
    "\n",
    "        projMatr1 = np.concatenate((I,z),axis=1) # Calculate matrix of extrinsic parameters ([R t]) of first camera\n",
    "\n",
    "        projMatr2 = np.concatenate((R,trans),axis=1) # Calculate matrix of extrinsic parameters ([R t]) of second camera\n",
    "\n",
    "        points_4d_hom = cv2.triangulatePoints(projMatr1, projMatr2, P1, P2) # Homogeneous coordinates \n",
    "        points_4d = points_4d_hom / np.tile(points_4d_hom[-1,:],(4,1)) # divide by fourth coordinate to get 3D points\n",
    "        points_3d = points_4d[:3,:].T # Take first three coordinates (3D points)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return points_3d\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.load_images()\n",
    "\n",
    "        # pair processing\n",
    "\n",
    "        # step 1 and 2: detect and match feature\n",
    "        p1, p2, matches_good, kp1, kp2 = self.detect_and_match_feature(\n",
    "            self.imgs[1], self.imgs[2])\n",
    "\n",
    "        self.visualize_matches(\n",
    "           self.imgs[1], self.imgs[2], kp1, kp2, matches_good,\n",
    "          save_path=join(self.output_dir, 'sift_match_01_7.png'))\n",
    "\n",
    "        # step 3: compute essential matrix\n",
    "        E, mask = self.compute_essential(p1, p2)\n",
    "\n",
    "        self.visualize_matches(\n",
    "            self.imgs[1], self.imgs[2], kp1, kp2, matches_good, mask=mask,\n",
    "           save_path=join(self.output_dir, 'inlier_match_01_7.png'))\n",
    "\n",
    "        self.visualize_epipolar_lines(\n",
    "           self.imgs[1], self.imgs[2], p1, p2, E,\n",
    "           save_path=join(self.output_dir, 'epipolar_lines_01_7.png')) \n",
    "\n",
    "        # step 4: recover pose\n",
    "        R, trans = self.compute_pose(p1, p2, E)\n",
    "        # step 5: triangulation\n",
    "        point_3d = self.triangulate(p1, p2, R, trans, mask)\n",
    "        # self.write_simple_obj(point_3d, point_rgb, filepath=join(\n",
    "        #     self.output_dir, 'output_01_7.obj')) # Output file to see point cloud in Meshlab. First two numbers (01) signify set of images used. Third number (7) gives threshold (here 0.7)\n",
    "        self.write_simple_pcd(point_3d, join(self.output_dir, 'temple1.pcd'))\n",
    "        \n",
    "def safe_mkdir(file_dir):\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.mkdir(file_dir)\n",
    "\n",
    "def intrinsic_reader(txt_file):\n",
    "    with open(txt_file) as f:\n",
    "        lines = f.readlines()\n",
    "    return np.array(\n",
    "        [l.strip().split(' ') for l in lines],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded img 0 size=(1224,1632): /home/somusan/OpencvUni/opencvblog/robotics-series/intro-to-slam-vo/src/Parallel_SFM/data/folder2/01.jpg\n",
      "loaded img 1 size=(1224,1632): /home/somusan/OpencvUni/opencvblog/robotics-series/intro-to-slam-vo/src/Parallel_SFM/data/folder2/02.jpg\n",
      "loaded img 2 size=(1224,1632): /home/somusan/OpencvUni/opencvblog/robotics-series/intro-to-slam-vo/src/Parallel_SFM/data/folder2/03.jpg\n",
      "(12111, 128)\n",
      "(9819, 128)\n",
      "Time for detect and match feature description 131.69222784042358\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    img_pattern = '/home/somusan/OpencvUni/opencvblog/robotics-series/intro-to-slam-vo/src/Parallel_SFM/data/folder2/*.jpg' \n",
    "    intrinsic = intrinsic_reader('/home/somusan/OpencvUni/opencvblog/robotics-series/intro-to-slam-vo/src/Parallel_SFM/data/folder2/intrinsics.txt') # Retrieve intrinsic parameters\n",
    "    output_dir = './output2' # Folder to save output results\n",
    "    safe_mkdir(output_dir)\n",
    "\n",
    "    sfm_solver = SFMSolver(img_pattern, intrinsic, output_dir, downscale=2)\n",
    "    sfm_solver.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Load the PCD file\n",
    "pcd_path = \"output2/temple1.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
