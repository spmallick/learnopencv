{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHoZdm7KuoTf",
        "outputId": "545dbba3-6826-4b8c-a947-3729308dd0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install ultralytics --quiet\n",
        "from ultralytics import YOLO\n",
        "!pip install kagglehub --quiet\n",
        "import kagglehub\n",
        "import cv2\n",
        "!pip install tqdm\n",
        "!pip install pillow\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "dataset_path = \"/content/HRSC2016-MS/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_dataset():\n",
        "    print(\"Downloading HRSC2016-MS dataset from Kaggle Hub...\")\n",
        "    path = kagglehub.dataset_download(\"weiming97/hrsc2016-ms-dataset\")\n",
        "    print(\"Path to dataset files:\", path)\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        os.makedirs(dataset_path)\n",
        "        os.system(f\"cp -r {path}/* {dataset_path}\")"
      ],
      "metadata": {
        "id": "gqxlmdV9u443"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_extract_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUDj2cJvu70f",
        "outputId": "42e170bf-ff0c-4ac6-e271-6d5fa45e35c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HRSC2016-MS dataset from Kaggle Hub...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/weiming97/hrsc2016-ms-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.34G/2.34G [00:21<00:00, 115MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/weiming97/hrsc2016-ms-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolo_dir(cwd):\n",
        "    yolo_dir = os.path.join(cwd, 'HRSC-YOLO')\n",
        "    os.mkdir(yolo_dir)\n",
        "    for i in ['train', 'val', 'test']:\n",
        "        folder = os.path.join(yolo_dir, i)\n",
        "        os.mkdir(folder)\n",
        "        for j in ['images', 'labels']:\n",
        "            subfolder = os.path.join(folder, j)\n",
        "            os.mkdir(subfolder)\n",
        "    return yolo_dir\n",
        "\n",
        "def xml2txt(xml_file_path, txt_file, w, h):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "    objs = root.findall('object')\n",
        "\n",
        "    if not objs:\n",
        "        print(f\"Warning: No objects found in {xml_file_path}. Creating an empty annotation file.\")\n",
        "        with open(txt_file, 'w') as f:\n",
        "            f.write(\"\\n\")  # Empty file for compatibility\n",
        "        return\n",
        "\n",
        "    with open(txt_file, 'w') as f:\n",
        "        for obj in objs:\n",
        "            try:\n",
        "                xmin = int(obj.find('bndbox/xmin').text)\n",
        "                ymin = int(obj.find('bndbox/ymin').text)\n",
        "                xmax = int(obj.find('bndbox/xmax').text)\n",
        "                ymax = int(obj.find('bndbox/ymax').text)\n",
        "\n",
        "                # Convert to YOLO format (normalized values)\n",
        "                x_center = (xmin + xmax) / (2.0 * w)\n",
        "                y_center = (ymin + ymax) / (2.0 * h)\n",
        "                box_w = (xmax - xmin) / w\n",
        "                box_h = (ymax - ymin) / h\n",
        "\n",
        "                # Save in YOLO format\n",
        "                f.write(f\"0 {x_center:.6f} {y_center:.6f} {box_w:.6f} {box_h:.6f}\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {xml_file_path}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def read_list_file(cwd):\n",
        "    with open(os.path.join(cwd, 'ImageSets/train.txt'), 'r') as f:\n",
        "        train_list = f.read().splitlines()\n",
        "    with open(os.path.join(cwd, 'ImageSets/val.txt'), 'r') as f:\n",
        "        val_list = f.read().splitlines()\n",
        "    with open(os.path.join(cwd, 'ImageSets/test.txt'), 'r') as f:\n",
        "        test_list = f.read().splitlines()\n",
        "    return train_list, val_list, test_list\n",
        "\n",
        "def construct_path(file_name, cwd, yolo_dir, mode):\n",
        "    if mode == 'train':\n",
        "        train_file_path = os.path.join(cwd, f'AllImages/{file_name}.bmp')\n",
        "        train_xml_path = os.path.join(cwd, f'Annotations/{file_name}.xml')\n",
        "        save_txt_path = os.path.join(yolo_dir, f'train/labels/{file_name}.txt')\n",
        "        save_png_path = os.path.join(yolo_dir, f'train/images/{file_name}.png')\n",
        "    elif mode == 'val':\n",
        "        train_file_path = os.path.join(cwd, f'AllImages/{file_name}.bmp')\n",
        "        train_xml_path = os.path.join(cwd, f'Annotations/{file_name}.xml')\n",
        "        save_txt_path = os.path.join(yolo_dir, f'val/labels/{file_name}.txt')\n",
        "        save_png_path = os.path.join(yolo_dir, f'val/images/{file_name}.png')\n",
        "    elif mode == 'test':\n",
        "        train_file_path = os.path.join(cwd, f'AllImages/{file_name}.bmp')\n",
        "        train_xml_path = os.path.join(cwd, f'Annotations/{file_name}.xml')\n",
        "        save_txt_path = os.path.join(yolo_dir, f'test/labels/{file_name}.txt')\n",
        "        save_png_path = os.path.join(yolo_dir, f'test/images/{file_name}.png')\n",
        "    else:\n",
        "        print(f\"Unrecognized mode {mode}!\")\n",
        "    return train_file_path, train_xml_path, save_txt_path, save_png_path\n",
        "\n",
        "\n",
        "def main():\n",
        "    cwd = os.getcwd()\n",
        "    yolo_dir = make_yolo_dir(cwd)\n",
        "\n",
        "    train_list, val_list, test_list = read_list_file(\"/content/HRSC2016-MS\")\n",
        "\n",
        "    for train_file in tqdm(train_list):\n",
        "        bmp_path, xml_path, txt_path, png_path = construct_path(train_file, \"/content/HRSC2016-MS\", yolo_dir, 'train')\n",
        "\n",
        "        img = Image.open(bmp_path)\n",
        "        w, h = img.size\n",
        "        xml2txt(xml_path, txt_path, w, h)\n",
        "\n",
        "        img.save(png_path, format='PNG')\n",
        "\n",
        "    for val_file in tqdm(val_list):\n",
        "        bmp_path, xml_path, txt_path, png_path = construct_path(val_file, \"/content/HRSC2016-MS\", yolo_dir, 'val')\n",
        "\n",
        "        img = Image.open(bmp_path)\n",
        "        w, h = img.size\n",
        "        xml2txt(xml_path, txt_path, w, h)\n",
        "\n",
        "        img.save(png_path, format='PNG')\n",
        "\n",
        "    for test_file in tqdm(test_list):\n",
        "        bmp_path, xml_path, txt_path, png_path = construct_path(test_file, \"/content/HRSC2016-MS\", yolo_dir, 'test')\n",
        "\n",
        "        img = Image.open(bmp_path)\n",
        "        w, h = img.size\n",
        "        xml2txt(xml_path, txt_path, w, h)\n",
        "\n",
        "        img.save(png_path, format='PNG')"
      ],
      "metadata": {
        "id": "fJlovl7Fu_j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_aQhpR_vV9W",
        "outputId": "7cc7e435-7177-4dd6-a52b-3dc8fc7f6e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|â–ˆâ–‰        | 115/610 [00:41<02:36,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000625.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|â–ˆâ–ˆâ–‹       | 164/610 [00:57<02:10,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000626.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 306/610 [01:47<01:42,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000628.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 335/610 [01:57<01:49,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000633.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 388/610 [02:15<01:18,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000702.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 464/610 [02:41<00:54,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000695.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 540/610 [03:08<00:24,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000686.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 610/610 [03:33<00:00,  2.86it/s]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 177/460 [01:01<01:48,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000624.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 201/460 [01:09<01:10,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000752.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 351/460 [02:04<00:38,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000671.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 354/460 [02:05<00:42,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000666.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 403/460 [02:23<00:17,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000639.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 451/460 [02:40<00:03,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000623.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [02:44<00:00,  2.80it/s]\n",
            "  3%|â–Ž         | 17/610 [00:08<04:39,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000029.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 33/610 [00:14<03:45,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000045.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|â–‹         | 42/610 [00:19<04:32,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000054.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|â–ˆâ–        | 85/610 [00:40<04:41,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000097.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|â–ˆâ–        | 86/610 [00:41<04:34,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000098.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|â–ˆâ–        | 88/610 [00:42<03:36,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000099.xml. Creating an empty annotation file.\n",
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000100.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|â–ˆâ–        | 89/610 [00:42<03:35,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000101.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|â–ˆâ–        | 90/610 [00:42<03:29,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000102.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|â–ˆâ–        | 91/610 [00:43<03:02,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000103.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 211/610 [01:23<01:19,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000222.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 450/610 [02:38<00:47,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000462.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 593/610 [03:25<00:03,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No objects found in /content/HRSC2016-MS/Annotations/100000605.xml. Creating an empty annotation file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 610/610 [03:32<00:00,  2.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = \"/content/HRSC-YOLO/\"\n",
        "dest_dir = \"/content/experimentals/\"\n",
        "\n",
        "# Create the 'experimentals' directory with 'images' and 'labels' subdirectories\n",
        "os.makedirs('experimentals', exist_ok=True)\n",
        "os.makedirs(os.path.join(dest_dir, \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dest_dir, \"labels\"), exist_ok=True)\n",
        "\n",
        "# Define dataset splits\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "# Copy all images and labels from HRSC-YOLO to experimentals\n",
        "def copy_files():\n",
        "    for split in splits:\n",
        "        image_source = os.path.join(source_dir, split, \"images\")\n",
        "        label_source = os.path.join(source_dir, split, \"labels\")\n",
        "\n",
        "        for file in os.listdir(image_source):\n",
        "            src_path = os.path.join(image_source, file)\n",
        "            dest_path = os.path.join(dest_dir, \"images\", file)\n",
        "            shutil.copy2(src_path, dest_path)\n",
        "\n",
        "        for file in os.listdir(label_source):\n",
        "            src_path = os.path.join(label_source, file)\n",
        "            dest_path = os.path.join(dest_dir, \"labels\", file)\n",
        "            shutil.copy2(src_path, dest_path)\n",
        "\n",
        "copy_files()\n",
        "print(\"All images and labels copied successfully to experimentals/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMHSRa9l7cR6",
        "outputId": "4c1c8e21-abfc-4360-a5a2-bda0c9f55892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images and labels copied successfully to experimentals/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "base_dir = \"/content/experimentals\"\n",
        "images_dir = os.path.join(base_dir, \"images\")\n",
        "labels_dir = os.path.join(base_dir, \"labels\")\n",
        "\n",
        "# Output directories\n",
        "output_dirs = {\n",
        "    \"train\": \"train\",\n",
        "    \"val\": \"val\",\n",
        "    \"test\": \"test\"\n",
        "}\n",
        "\n",
        "# Create train, val, and test directories with images and labels subfolders\n",
        "for split in output_dirs.values():\n",
        "    os.makedirs(os.path.join(split, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(split, \"labels\"), exist_ok=True)\n",
        "\n",
        "# Get all image filenames\n",
        "image_files = [f for f in os.listdir(images_dir) if f.endswith(\".png\")]\n",
        "random.shuffle(image_files)  # Shuffle dataset\n",
        "\n",
        "# Define split sizes\n",
        "train_size, val_size, test_size = 610, 460, 610\n",
        "\n",
        "# Split dataset\n",
        "train_images = image_files[:train_size]\n",
        "val_images = image_files[train_size:train_size + val_size]\n",
        "test_images = image_files[train_size + val_size:train_size + val_size + test_size]\n",
        "\n",
        "# Function to copy files\n",
        "def copy_files(image_list, split):\n",
        "    for img_name in image_list:\n",
        "        label_name = img_name.replace(\".png\", \".txt\")  # Corresponding label\n",
        "        shutil.copy(os.path.join(images_dir, img_name), os.path.join(split, \"images\", img_name))\n",
        "        shutil.copy(os.path.join(labels_dir, label_name), os.path.join(split, \"labels\", label_name))\n",
        "\n",
        "# Copy files to respective folders\n",
        "copy_files(train_images, \"train\")\n",
        "copy_files(val_images, \"val\")\n",
        "copy_files(test_images, \"test\")\n",
        "\n",
        "print(\"Dataset split and copied successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1YsV2UvXYA",
        "outputId": "c66c21e4-2257-4f9d-a4af-70e9fd924984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split and copied successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_dir2 = \"/content\""
      ],
      "metadata": {
        "id": "RDFiBw6svl7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = os.path.join(yolo_dir2, \"data.yaml\")"
      ],
      "metadata": {
        "id": "EQr6NKVxvogR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_yaml():\n",
        "    yaml_content = f\"\"\"\n",
        "train: {os.path.join(yolo_dir2, 'train/images')}\n",
        "val: {os.path.join(yolo_dir2, 'val/images')}\n",
        "test: {os.path.join(yolo_dir2, 'test/images')}\n",
        "\n",
        "nc: 1\n",
        "names: ['ship']\n",
        "\"\"\"\n",
        "    with open(data_yaml, \"w\") as f:\n",
        "        f.write(yaml_content)\n",
        "    print(\"Generated corrected data.yaml file.\")"
      ],
      "metadata": {
        "id": "s_0noYKcvrMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_data_yaml()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3uyUcrsvsFj",
        "outputId": "59a71e7d-b0a2-420d-b280-a70ec7c84d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated corrected data.yaml file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the YOLOv11-large model weights file from https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt and upload to the colab session\n",
        "\n",
        "yolov11_model_path = \"/content/yolo11l.pt\""
      ],
      "metadata": {
        "id": "Mo1u42Fnv_Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolov11(epochs=100, batch_size=8):\n",
        "    model = YOLO(yolov11_model_path)\n",
        "    model.train(data=data_yaml, epochs=epochs, batch=batch_size, imgsz=640, device='cuda', workers=4, save=True, save_period=10)\n",
        "    model.val()\n",
        "    print(model)\n",
        "    print(\"YOLOv12 training completed on HRSC2016-MS.\")"
      ],
      "metadata": {
        "id": "OMgKKfG3wABz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_yolov11()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tKYZyk0-wLQ7",
        "outputId": "006ebc38-edb5-41c3-8422-f6e516512b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.83 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolo11l.pt, data=/content/data.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=10, cache=False, device=cuda, workers=4, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
            " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
            "YOLO11l summary: 357 layers, 25,311,251 parameters, 25,311,235 gradients, 87.3 GFLOPs\n",
            "\n",
            "Transferred 1009/1015 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 610 images, 13 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 610/610 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/val/labels.cache... 460 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100       8.8G      1.374      3.102       1.46         83        640:  13%|â–ˆâ–Ž        | 10/77 [00:06<00:43,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b5f21ad17382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_yolov11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-109dad36a0cb>\u001b[0m in \u001b[0;36mtrain_yolov11\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_yolov11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myolov11_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_yolov11(image_path, model_weights=\"path_to_the_saved_model_weights_(can_be_found_at_runs/detect/trainx/weights/best.pt\"):\n",
        "    model = YOLO(model_weights)\n",
        "    results = model(image_path)\n",
        "    for result in results:\n",
        "        img = cv2.imread(image_path)\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = box.conf[0].item()\n",
        "            cls = int(box.cls[0])\n",
        "            label = f\"{model.names[cls]} {conf:.2f}\"\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "kLEnTsMn9V1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = \"path_to_the_image_file\"\n",
        "infer_yolov11(test_image)"
      ],
      "metadata": {
        "id": "EF3HEGSx9X27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate mAP scores for the validation set\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"path_to_the_saved_model_weights_(can_be_found_at_runs/detect/trainx/weights/best.pt\")\n",
        "\n",
        "metrics = model.val(data=data_yaml)\n",
        "print(metrics.box.map)\n",
        "print(metrics.box.map50)\n",
        "print(metrics.box.map75)"
      ],
      "metadata": {
        "id": "OhijbJbGwsdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# over-write data.yaml and exchange the paths assigned to test and valid with each other\n",
        "# calculate mAP scores for the test set\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"path_to_the_saved_model_weights_(can_be_found_at_runs/detect/trainx/weights/best.pt\")\n",
        "\n",
        "metrics = model.val(data=data_yaml)\n",
        "print(metrics.box.map)\n",
        "print(metrics.box.map50)\n",
        "print(metrics.box.map75)"
      ],
      "metadata": {
        "id": "aHPUEAXMw4jm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}