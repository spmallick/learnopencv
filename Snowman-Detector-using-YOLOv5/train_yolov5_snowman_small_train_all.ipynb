{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KB_Ha_gYEJr7"},"outputs":[],"source":["import os\n","import glob as glob\n","import cv2\n","import matplotlib.pyplot as plt\n","import requests\n","import zipfile"]},{"cell_type":"markdown","metadata":{"id":"QfcCpGJbEJr_"},"source":["## Constant/Config Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sttqmPHLEJsA"},"outputs":[],"source":["# Whether to carry out training or not,\n","# if `false`, running the whole notebook will carry out\n","# inference on the last trained model automatically\n","TRAIN = True\n","# Number of epochs to train for.\n","EPOCHS = 5"]},{"cell_type":"markdown","metadata":{"id":"jeS8zcZXipce"},"source":["## Ultralytics Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cNe67H4iz-3","outputId":"dfa54e38-e1a3-467d-d9ca-e8716df0ed97","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639890683841,"user_tz":-330,"elapsed":2309,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 10239, done.\u001b[K\n","remote: Total 10239 (delta 0), reused 0 (delta 0), pack-reused 10239\u001b[K\n","Receiving objects: 100% (10239/10239), 10.50 MiB | 20.91 MiB/s, done.\n","Resolving deltas: 100% (7078/7078), done.\n"]}],"source":["#### RUN THIS ONCE TO CLONE THE YOLOV5 REPO ####\n","if not os.path.exists('yolov5'):\n","    !git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T17815SvEJsB","executionInfo":{"status":"ok","timestamp":1639890683843,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"7680f7f4-bfe7-4ee8-a867-eea51e1e1c8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}],"source":["%cd yolov5/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzrSpHgdEJsC","executionInfo":{"status":"ok","timestamp":1639890684473,"user_tz":-330,"elapsed":639,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"f0715d04-4d90-4d26-b227-cd663dd381e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}],"source":["!pwd"]},{"cell_type":"markdown","metadata":{"id":"mgzh0e4gjFDQ"},"source":["## Dataset Download"]},{"cell_type":"markdown","metadata":{"id":"rw9hjyAUEJsE"},"source":["Here, we will download the Snowman dataset images and labels. The two folders that will be downloaded will contain all the images and labels that we need."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXgHRhsHEJsF"},"outputs":[],"source":["def download_file(url, save_name):\n","    url = url\n","    if not os.path.exists(save_name):\n","        file = requests.get(url)\n","\n","        open(save_name, 'wb').write(file.content)\n","    \n","download_file('https://learnopencv.s3.us-west-2.amazonaws.com/snowman-dataset.zip', 'snowman_dataset.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1-mDvY8EJsG","executionInfo":{"status":"ok","timestamp":1639890690436,"user_tz":-330,"elapsed":1540,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"71a3ffdc-3820-4099-a6da-9ad028ae45c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted all\n"]}],"source":["zip_file = 'snowman_dataset.zip'\n","\n","if not os.path.exists('JPEGImages_and_Labels'):\n","    try:\n","        with zipfile.ZipFile(zip_file) as z:\n","            z.extractall(\"./\")\n","            print(\"Extracted all\")\n","    except:\n","        print(\"Invalid file\")"]},{"cell_type":"markdown","metadata":{"id":"SMGGIrZsEJsG"},"source":["## Prepare Final Dataset in YOLOv5 Format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2osWXFDEJsG"},"outputs":[],"source":["# Create an `images` and a `labels` directory in `snowman_data`.\n","os.makedirs('snowman_data', exist_ok=True)\n","os.makedirs('snowman_data/labels', exist_ok=True)\n","os.makedirs('snowman_data/images', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvEewlgqEJsH"},"outputs":[],"source":["# Create training and validation split directories.\n","os.makedirs('snowman_data/images/train', exist_ok=True)\n","os.makedirs('snowman_data/images/val', exist_ok=True)\n","\n","os.makedirs('snowman_data/labels/train', exist_ok=True)\n","os.makedirs('snowman_data/labels/val', exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"WW1LD8IYEJsH"},"source":["### Train-Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4RuRLtSEJsH","executionInfo":{"status":"ok","timestamp":1639890690439,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"90ad5914-ec46-4f62-9740-6d8565ef3fc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing splitTrainAndTest.py\n"]}],"source":["%%writefile splitTrainAndTest.py\n","import random\n","import os\n","import subprocess\n","import sys\n","\n","def split_data_set(image_dir):\n","\n","    f_val = open(\"snowman_test.txt\", 'w')\n","    f_train = open(\"snowman_train.txt\", 'w')\n","    \n","    path, dirs, files = next(os.walk(image_dir))\n","    data_size = len(files)\n","\n","    ind = 0\n","    data_test_size = int(0.1 * data_size)\n","    test_array = random.sample(range(data_size), k=data_test_size)\n","    \n","    for f in os.listdir(image_dir):\n","        if(f.split(\".\")[1] == \"jpg\"):\n","            ind += 1\n","            \n","            if ind in test_array:\n","                f_val.write(image_dir+'/'+f+'\\n')\n","            else:\n","                f_train.write(image_dir+'/'+f+'\\n')\n","\n","\n","split_data_set(sys.argv[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUbEBf55EJsI"},"outputs":[],"source":["!python splitTrainAndTest.py JPEGImages_and_Labels/JPEGImages"]},{"cell_type":"markdown","metadata":{"id":"9uJg11hbEJsI"},"source":["### Put the Images and Labels in the Respective Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRZOJz1FEJsJ"},"outputs":[],"source":["import shutil\n","\n","# For training data.\n","def copy_image_and_txt_train(path_text_file):\n","    with open(path_text_file, 'r') as f:\n","        file_paths = f.readlines()\n","        file_paths = [file_path.split('.')[0].split('/')[-1] for file_path in file_paths]\n","        # Copy images\n","        for file_path in file_paths:\n","            shutil.copy(\n","                f\"JPEGImages_and_Labels/JPEGImages/{file_path}.jpg\", \n","                f\"snowman_data/images/train/{file_path}.jpg\"\n","            )\n","        # Copy text\n","            shutil.copy(\n","                f\"JPEGImages_and_Labels/labels/{file_path}.txt\", \n","                f\"snowman_data/labels/train/{file_path}.txt\"\n","            )\n","\n","copy_image_and_txt_train('snowman_train.txt')\n","\n","# For validation data.\n","def copy_image_and_txt_test(path_text_file):\n","    with open(path_text_file, 'r') as f:\n","        file_paths = f.readlines()\n","        file_paths = [file_path.split('.')[0].split('/')[-1] for file_path in file_paths]\n","        # Copy images\n","        for file_path in file_paths:\n","            shutil.copy(\n","                f\"JPEGImages_and_Labels/JPEGImages/{file_path}.jpg\", \n","                f\"snowman_data/images/val/{file_path}.jpg\"\n","            )\n","        # Copy text\n","            shutil.copy(\n","                f\"JPEGImages_and_Labels/labels/{file_path}.txt\", \n","                f\"snowman_data/labels/val/{file_path}.txt\"\n","            )\n","\n","copy_image_and_txt_test('snowman_test.txt')"]},{"cell_type":"markdown","metadata":{"id":"hxinUc7zEJsJ"},"source":["### Prepare the YAML File Containing the Paths for YOLOv5 Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9cbqdECEJsK","executionInfo":{"status":"ok","timestamp":1639890691592,"user_tz":-330,"elapsed":35,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"7d776ce8-2567-4fd2-b9a5-8343ce9fee72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Argoverse.yaml\tGlobalWheat2020.yaml  Objects365.yaml  VisDrone.yaml\n","coco128.yaml\thyps\t\t      scripts\t       VOC.yaml\n","coco.yaml\timages\t\t      SKU-110K.yaml    xView.yaml\n"]}],"source":["!ls data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2nAD897EJsK","executionInfo":{"status":"ok","timestamp":1639890691593,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"6e4aa2f5-483b-44bf-89d1-619203ab99ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing data/snowman.yaml\n"]}],"source":["%%writefile data/snowman.yaml\n","\n","path: snowman_data # dataset root dir\n","train: images/train  # train images (relative to 'path') \n","val: images/val  # val images (relative to 'path')\n","test:  # test images (optional)\n","\n","# Classes\n","nc: 1  # number of classes\n","names: ['snowman']  # class names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8U3IbxfGEJsK","executionInfo":{"status":"ok","timestamp":1639890692022,"user_tz":-330,"elapsed":437,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"92a6c0c5-3c20-4202-f688-f65c3bf7cc0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Argoverse.yaml\t      hyps\t       SKU-110K.yaml  xView.yaml\n","coco128.yaml\t      images\t       snowman.yaml\n","coco.yaml\t      Objects365.yaml  VisDrone.yaml\n","GlobalWheat2020.yaml  scripts\t       VOC.yaml\n"]}],"source":["!ls data"]},{"cell_type":"markdown","metadata":{"id":"MafUzkJvEJsK"},"source":["## Start the Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehCy7e4iEJsL","executionInfo":{"status":"ok","timestamp":1639890692023,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"986a8bc5-d266-4e50-a622-7e0c0dfb3631"},"outputs":[{"output_type":"stream","name":"stdout","text":["models/yolov5l.yaml  models/yolov5n.yaml  models/yolov5x.yaml\n","models/yolov5m.yaml  models/yolov5s.yaml\n"]}],"source":["#### CHOOSE BETWEEN Nano, Small, Regular, Large, and Xtra large Models.\n","!ls models/*.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NksNYvatEJsL","executionInfo":{"status":"ok","timestamp":1639890692024,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"512d4a5d-e2aa-4208-f984-aea69bb5e0d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current number of result directories: 0\n"]}],"source":["# Directory to store results\n","res_dir_count = len(glob.glob('runs/train/*'))\n","print(f\"Current number of result directories: {res_dir_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53l1uoyHEJsL","executionInfo":{"status":"ok","timestamp":1639890692024,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"b191b0c3-ec18-4d4d-b01e-8d924d69e2a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["results1\n"]}],"source":["if TRAIN:\n","    RES_DIR = f\"results{res_dir_count+1}\"\n","    print(RES_DIR)\n","else:\n","    RES_DIR = f\"results{res_dir_count}\""]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EQZATl4Eqxi","executionInfo":{"status":"ok","timestamp":1639890699655,"user_tz":-330,"elapsed":7640,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"6a397af9-7307-4067-d6ea-29b4249a903c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Collecting PyYAML>=5.3.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n","Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.12.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.42.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n","Installing collected packages: thop, PyYAML\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuev6wlfEJsL","executionInfo":{"status":"ok","timestamp":1639890995478,"user_tz":-330,"elapsed":295834,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"370a097b-a9cf-4cba-9d93-a4b397a3e366"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=snowman.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=results1, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.0-151-gabbdd48 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt to yolov5s.pt...\n","100% 14.0M/14.0M [00:00<00:00, 98.3MB/s]\n","\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.8 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'snowman_data/labels/train' images and labels...485 found, 0 missing, 0 empty, 0 corrupted: 100% 485/485 [00:00<00:00, 1484.08it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: snowman_data/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'snowman_data/labels/val' images and labels...53 found, 0 missing, 0 empty, 0 corrupted: 100% 53/53 [00:00<00:00, 417.87it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: snowman_data/labels/val.cache\n","Plotting labels to runs/train/results1/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.51 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/results1\u001b[0m\n","Starting training for 5 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/4     3.23G    0.1065   0.03521         0        27       640: 100% 31/31 [00:45<00:00,  1.47s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.54s/it]\n","                 all         53         87     0.0661      0.195     0.0346    0.00656\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/4      3.7G   0.08606   0.03413         0        12       640: 100% 31/31 [00:43<00:00,  1.40s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.20s/it]\n","                 all         53         87      0.245      0.333      0.178     0.0446\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/4      3.7G   0.07279   0.03363         0        10       640: 100% 31/31 [00:42<00:00,  1.38s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.11s/it]\n","                 all         53         87      0.508      0.448      0.383      0.129\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/4      3.7G   0.06455   0.03283         0        16       640: 100% 31/31 [00:43<00:00,  1.40s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.03s/it]\n","                 all         53         87      0.543      0.586      0.533      0.188\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/4      3.7G   0.06299   0.02877         0        11       640: 100% 31/31 [00:42<00:00,  1.37s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.04s/it]\n","                 all         53         87      0.697      0.528      0.578      0.239\n","\n","5 epochs completed in 0.066 hours.\n","Optimizer stripped from runs/train/results1/weights/last.pt, 14.4MB\n","Optimizer stripped from runs/train/results1/weights/best.pt, 14.4MB\n","\n","Validating runs/train/results1/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.74s/it]\n","                 all         53         87      0.687      0.529      0.587      0.244\n","Results saved to \u001b[1mruns/train/results1\u001b[0m\n"]}],"source":["### TRAINING A Small MODEL ###\n","# The chosen pretrained model will be downloaded automatically.\n","if TRAIN:\n","    !python train.py --img 640 --batch 16 --epochs {EPOCHS} --data snowman.yaml --weights yolov5s.pt --name {RES_DIR}"]},{"cell_type":"markdown","metadata":{"id":"22XYv0yOEJsM"},"source":["## Check Out the Validation Predictions Saved During Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HSL3pc-EJsM","executionInfo":{"status":"ok","timestamp":1639890995478,"user_tz":-330,"elapsed":39,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"59d8aff4-d397-4c5a-f336-ba234dfee045"},"outputs":[{"output_type":"stream","name":"stdout","text":["confusion_matrix.png\t\t\t\t   results.csv\n","events.out.tfevents.1639890713.0a0fe6886d38.152.0  results.png\n","F1_curve.png\t\t\t\t\t   train_batch0.jpg\n","hyp.yaml\t\t\t\t\t   train_batch1.jpg\n","labels_correlogram.jpg\t\t\t\t   train_batch2.jpg\n","labels.jpg\t\t\t\t\t   val_batch0_labels.jpg\n","opt.yaml\t\t\t\t\t   val_batch0_pred.jpg\n","P_curve.png\t\t\t\t\t   val_batch1_labels.jpg\n","PR_curve.png\t\t\t\t\t   val_batch1_pred.jpg\n","R_curve.png\t\t\t\t\t   weights\n"]}],"source":["!ls runs/train/{RES_DIR}"]},{"cell_type":"markdown","metadata":{"id":"zgdPoaBWEJsM"},"source":["**Each experiment will be stores in `results<num>` directory. The most recent experiment is stored in `results<highest_number>` folder. For example, `results1`, `results2`, `results3`, and so on**. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4UejDz3EJsM","executionInfo":{"status":"ok","timestamp":1639890995479,"user_tz":-330,"elapsed":25,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"e1b88a94-efd5-4c4e-eceb-4d218fab755c"},"outputs":[{"output_type":"stream","name":"stdout","text":["confusion_matrix.png\t\t\t\t   results.csv\n","events.out.tfevents.1639890713.0a0fe6886d38.152.0  results.png\n","F1_curve.png\t\t\t\t\t   train_batch0.jpg\n","hyp.yaml\t\t\t\t\t   train_batch1.jpg\n","labels_correlogram.jpg\t\t\t\t   train_batch2.jpg\n","labels.jpg\t\t\t\t\t   val_batch0_labels.jpg\n","opt.yaml\t\t\t\t\t   val_batch0_pred.jpg\n","P_curve.png\t\t\t\t\t   val_batch1_labels.jpg\n","PR_curve.png\t\t\t\t\t   val_batch1_pred.jpg\n","R_curve.png\t\t\t\t\t   weights\n"]}],"source":["!ls runs/train/{RES_DIR}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNtjs5pxEJsM","executionInfo":{"status":"ok","timestamp":1639890995479,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"6ff0f01a-c4ec-4fc9-8fd1-ddbe1348f7f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["['runs/train/results1/val_batch1_pred.jpg', 'runs/train/results1/val_batch0_pred.jpg']\n"]}],"source":["EXP_PATH = f\"runs/train/{RES_DIR}\"\n","validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n","print(validation_pred_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1GU-kkMTLU9dIdxV6CkqGDACuKwKb8oCY"},"id":"llBqcbooEJsN","executionInfo":{"status":"ok","timestamp":1639891000700,"user_tz":-330,"elapsed":5232,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"a5da06f0-9428-457c-fa38-9c64e7b6c7f3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for pred_image in validation_pred_images:\n","    image = cv2.imread(pred_image)\n","    plt.figure(figsize=(19, 16))\n","    plt.imshow(image[:, :, ::-1])\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-oUO7tTVEJsN"},"source":["## Inference\n","In this section, we will carry out inference on unseen images and videos from the internet. \n","\n","The images for inference are in the `inference_images` directory.\n","\n","The videos for inference are in the `inference_videos` directory."]},{"cell_type":"markdown","metadata":{"id":"9bMLH2TDEJsN"},"source":["### Download the Images and Videos\n","Let's download the images and videos that we will carry inference upon."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M822mbWGEJsN"},"outputs":[],"source":["os.makedirs('inference_images', exist_ok=True)\n","os.makedirs('inference_videos', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SagmQLPmEJsN"},"outputs":[],"source":["download_file('https://pixabay.com/get/g56ba59637d3bbfcf738798be157376e22985aa2233f2b67b22f7909190729874e797ade2a566ba708b812db9c3e0cfdbbceba1ce77c779f829e798695883ed91e26a338d7ad478074ae5c8878d5cb331_1920.jpg'\n","              , 'inference_images/images_1.jpg')\n","download_file('https://pixabay.com/get/g200d6c9606544f56332644d0b5eeff69bb601f222ba4ac4e120da6f827cd5d0470aa04cad84e704c4ac71427732cb9616d418a18fb704445027ac2caef968101f156fe1d6079b0292133def33cc910e5_1920.jpg'\n","              , 'inference_images/images_2.jpg')\n","\n","download_file('https://vod-progressive.akamaized.net/exp=1639902174~acl=%2Fvimeo-prod-skyfire-std-us%2F01%2F152%2F20%2F500762856%2F2280358008.mp4~hmac=c4a268ba04e78571201a8f605985e5afe7143b48b51ec65699a0d839cabb21f3/vimeo-prod-skyfire-std-us/01/152/20/500762856/2280358008.mp4?filename=Snowman+-+55410.mp4'\n","              , 'inference_videos/video_1.mp4')"]},{"cell_type":"markdown","metadata":{"id":"EZ42yaapEJsO"},"source":["### Inference on Images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuIGusb9EJsO","executionInfo":{"status":"ok","timestamp":1639891000701,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"b3bd8866-8edf-45b6-bd9e-57a7672c655c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current number of inference detection directories: 0\n","inference1\n"]}],"source":["# Directory to store inference results\n","infer_dir_count = len(glob.glob('runs/detect/*'))\n","print(f\"Current number of inference detection directories: {infer_dir_count}\")\n","INFER_DIR = f\"inference{infer_dir_count+1}\"\n","print(INFER_DIR)"]},{"cell_type":"markdown","metadata":{"id":"O8k-XjooEJsO"},"source":["**For inference on images, we can just provide the directory path where all the images are stored, and inference will happen on all images automatically**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MFVM0uREJsO","executionInfo":{"status":"ok","timestamp":1639891004526,"user_tz":-330,"elapsed":3836,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"8e85eecd-5648-48c2-f527-db7960732ec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/results1/weights/best.pt'], source=inference_images, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=inference1, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 🚀 v6.0-151-gabbdd48 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/2 /content/yolov5/inference_images/images_1.jpg: 384x640 1 snowman, Done. (0.022s)\n","image 2/2 /content/yolov5/inference_images/images_2.jpg: 352x640 4 snowmans, Done. (0.020s)\n","Speed: 0.4ms pre-process, 21.0ms inference, 3.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/inference1\u001b[0m\n"]}],"source":["# Inference on images.\n","!python detect.py --weights runs/train/{RES_DIR}/weights/best.pt \\\n","--source inference_images --name {INFER_DIR}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPdF3NUvEJsO","executionInfo":{"status":"ok","timestamp":1639891004912,"user_tz":-330,"elapsed":398,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"681d056f-7326-4acf-a4f5-7e7429693a05"},"outputs":[{"output_type":"stream","name":"stdout","text":["['runs/detect/inference1/images_1.jpg', 'runs/detect/inference1/images_2.jpg']\n"]}],"source":["# Visualize infernece images.\n","INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n","infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n","print(infer_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1efpwG4ZxRLqUAg_gRavQCr5NniIjEyKj"},"id":"FL6g-VPbEJsO","executionInfo":{"status":"ok","timestamp":1639891010057,"user_tz":-330,"elapsed":5147,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"ebf6239e-cbf1-44ec-fddd-ffaf769d1442"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for pred_image in infer_images:\n","    image = cv2.imread(pred_image)\n","    plt.figure(figsize=(19, 16))\n","    plt.imshow(image[:, :, ::-1])\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"yEPgA7esEJsP"},"source":["### Inference on Videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWVCU4C0EJsP","executionInfo":{"status":"ok","timestamp":1639891010059,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"2a1943c3-00e8-45dc-d84f-89f6fd9b652c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current number of inference detection directories: 1\n","inference2\n"]}],"source":["# Directory to store inference results\n","infer_dir_count = len(glob.glob('runs/detect/*'))\n","print(f\"Current number of inference detection directories: {infer_dir_count}\")\n","INFER_DIR = f\"inference{infer_dir_count+1}\"\n","print(INFER_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SOoG1DgEJsP","executionInfo":{"status":"ok","timestamp":1639891024835,"user_tz":-330,"elapsed":14787,"user":{"displayName":"Sovit Rath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15729028473288306186"}},"outputId":"fc505451-849e-4a60-9614-fa481c017a3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/results1/weights/best.pt'], source=inference_videos, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=inference2, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 🚀 v6.0-151-gabbdd48 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","video 1/1 (1/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.020s)\n","video 1/1 (2/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (3/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (4/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (5/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (6/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (7/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (8/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (9/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (10/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (11/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (12/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (13/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (14/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (15/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (16/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (17/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (18/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (19/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (20/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (21/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (22/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (23/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (24/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (25/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (26/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (27/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (28/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (29/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (30/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (31/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (32/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (33/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (34/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (35/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (36/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (37/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (38/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (39/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (40/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (41/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (42/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (43/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (44/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (45/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (46/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (47/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (48/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (49/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (50/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (51/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (52/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (53/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (54/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (55/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (56/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (57/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (58/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (59/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (60/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (61/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (62/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (63/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (64/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (65/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (66/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.019s)\n","video 1/1 (67/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (68/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (69/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (70/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (71/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (72/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (73/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (74/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (75/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (76/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (77/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (78/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (79/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (80/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (81/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (82/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (83/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (84/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (85/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (86/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (87/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (88/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (89/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (90/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (91/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (92/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (93/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.019s)\n","video 1/1 (94/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (95/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (96/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (97/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (98/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (99/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (100/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (101/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (102/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (103/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (104/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (105/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (106/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (107/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (108/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (109/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (110/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (111/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (112/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (113/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (114/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (115/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (116/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (117/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (118/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (119/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (120/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (121/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (122/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (123/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (124/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (125/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (126/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (127/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (128/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (129/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (130/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (131/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (132/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (133/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (134/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (135/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (136/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (137/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (138/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (139/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (140/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (141/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.019s)\n","video 1/1 (142/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (143/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (144/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (145/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (146/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (147/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (148/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (149/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (150/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (151/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (152/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (153/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (154/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (155/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (156/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (157/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (158/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (159/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (160/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (161/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (162/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (163/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (164/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (165/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (166/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (167/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (168/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (169/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (170/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.023s)\n","video 1/1 (171/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (172/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (173/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (174/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (175/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (176/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.021s)\n","video 1/1 (177/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.028s)\n","video 1/1 (178/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (179/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (180/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 5 snowmans, Done. (0.018s)\n","video 1/1 (181/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (182/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 4 snowmans, Done. (0.018s)\n","video 1/1 (183/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (184/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (185/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","video 1/1 (186/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (187/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (188/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (189/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (190/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (191/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (192/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (193/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (194/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (195/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (196/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (197/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (198/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (199/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (200/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (201/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (202/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (203/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (204/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (205/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (206/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (207/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (208/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (209/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (210/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (211/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (212/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (213/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (214/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (215/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (216/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (217/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (218/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (219/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (220/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (221/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (222/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (223/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (224/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (225/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (226/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (227/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (228/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (229/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (230/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (231/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (232/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (233/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (234/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (235/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (236/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (237/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (238/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (239/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (240/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (241/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (242/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (243/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (244/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (245/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (246/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (247/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (248/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (249/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (250/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (251/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (252/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (253/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.019s)\n","video 1/1 (254/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (255/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (256/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (257/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.020s)\n","video 1/1 (258/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (259/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (260/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (261/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (262/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (263/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (264/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (265/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (266/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (267/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (268/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (269/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (270/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (271/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (272/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (273/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (274/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (275/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (276/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (277/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (278/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (279/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (280/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (281/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (282/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (283/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (284/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (285/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (286/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (287/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (288/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (289/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (290/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (291/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (292/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (293/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.019s)\n","video 1/1 (294/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (295/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (296/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (297/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 Done. (0.018s)\n","video 1/1 (298/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 1 snowman, Done. (0.018s)\n","video 1/1 (299/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 2 snowmans, Done. (0.018s)\n","video 1/1 (300/300) /content/yolov5/inference_videos/video_1.mp4: 384x640 3 snowmans, Done. (0.018s)\n","Speed: 0.4ms pre-process, 18.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/inference2\u001b[0m\n"]}],"source":["# Inference on images.\n","!python detect.py --weights runs/train/{RES_DIR}/weights/best.pt \\\n","--source inference_videos --name {INFER_DIR}"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"train_yolov5_snowman_final.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}