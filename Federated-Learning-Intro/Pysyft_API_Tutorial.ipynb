{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic API details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pysyft using `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install syft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import PyTorch and PySyft, however we hook torch with syft with `TorchHook` function. The `TorchHook` does the wrapping by adding all the additional functionality to PyTorch for doing Federated Learning and other Private AI techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch) # add extra functionality to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a virtual machine owned by some health clinic, say `harmony_clinic`. We will be using this to simulate a machine present at a remote location. A thing to note is that syft calls these machines as `VirtualWorker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a machine owned by harmony clinic\n",
    "harmony_clinic = sy.VirtualWorker(hook=hook,id='clinic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`harmony_clinic` is at a remote location but it doesn't have any data we can use. Let's create some data so that we can send it to `harmony_clinic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:37078163247 -> clinic:73951623209]\n"
     ]
    }
   ],
   "source": [
    "# we create a Tensor, maybe this is some gene sequence\n",
    "dna = torch.tensor([0,1,2,1,2])\n",
    "\n",
    "# and now I send it, and in turn we get a pointer back that\n",
    "# points to that Tensor\n",
    "dna_ptr = dna.send(harmony_clinic)\n",
    "\n",
    "print(dna_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- wp:paragraph -->\n",
    "<p>We see that the&nbsp;<code>PointerTensor</code>&nbsp;points from&nbsp;<code>me</code>&nbsp;(which is us, PySyft creates this&nbsp;<code>me</code>&nbsp;worker automatically) to&nbsp;<code>harmony_clinic</code>. We also see some random numbers, these are actually object IDs that PySyft assigns to every object.</p> Notice the object ID for the tensor dna. It is same as above in <code>dna_ptr</code>.\n",
    "<!-- /wp:paragraph -->\n",
    "\n",
    "<!-- wp:paragraph -->\n",
    "<p>Now&nbsp;<code>harmony_clinic</code> has the tensor that we sent. We can use&nbsp;<code>harmony_clinic._objects</code>&nbsp;to see objects that&nbsp;<code><code>harmony_clinic</code></code>currently has.</p>\n",
    "<!-- /wp:paragraph -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{73951623209: tensor([0, 1, 2, 1, 2])}\n"
     ]
    }
   ],
   "source": [
    "print(harmony_clinic._objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the same way, we can get a tensor back from a remote location by using the `.get()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 1, 2])\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# get back dna\n",
    "dna = dna_ptr.get()\n",
    "print(dna)\n",
    "\n",
    "# And as you can see... clinic no longer has the tensor dna anymore!!! It has moved back to our machine!\n",
    "print(harmony_clinic._objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:36395876027 -> clinic:33335259535]\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3.14, 6.28]).send(harmony_clinic)\n",
    "b = torch.tensor([6.14, 3.28]).send(harmony_clinic)\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something very interesting happened behind the scenes, i.e. when did `c = a + b` on our machine, a command was sent to the remote machine that did that exact calculation, created a new tensor on its machine and then sent back a pointer to us which we now call `c`.\n",
    "\n",
    "<!-- wp:paragraph -->\n",
    "<p>The amazing thing is this API has been extended to all the PyTorch operations including Back propogation. Hurray !!</p>\n",
    "<!-- /wp:paragraph -->\n",
    "\n",
    "<!-- wp:paragraph -->\n",
    "<p>This means that we can use the same PyTorch code that we usually do when doing Machine Learning.</p>\n",
    "<!-- /wp:paragraph -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4000, 6.2000], requires_grad=True)\n",
      "tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# we create two tensors and send it to bob\n",
    "train = torch.tensor([2.4, 6.2], requires_grad=True).send(harmony_clinic)\n",
    "label = torch.tensor([2, 6.]).send(harmony_clinic)\n",
    "\n",
    "# we apply some function, in this case a rather simple one, just to show the idea, we use L1 loss\n",
    "loss = (train-label).abs().sum()\n",
    "\n",
    "# Yes, even .backward() works when working with Pointers\n",
    "loss.backward()\n",
    "\n",
    "# now we retreive back the train tensor\n",
    "train = train.get()\n",
    "\n",
    "print(train)\n",
    "\n",
    "# If everything went well, we will see gradients accumulated \n",
    "# in .grad attribute of train\n",
    "print(train.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
