{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install numpy scikit-image scipy scikit-learn matplotlib tqdm tensorflow torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from shutil import copyfile\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import printoptions\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds to make experiments reproducible.\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the .tar.gz archive from this(https://github.com/thuml/HashNet/tree/master/pytorch#datasets) \n",
    "# github repository to speed up image loading(instead of loading it from Flickr).\n",
    "# Let's download and extract it.\n",
    "img_folder = 'images'\n",
    "if not os.path.exists(img_folder):\n",
    "    def download_file_from_google_drive(id, destination):\n",
    "        def get_confirm_token(response):\n",
    "            for key, value in response.cookies.items():\n",
    "                if key.startswith('download_warning'):\n",
    "                    return value\n",
    "            return None\n",
    "\n",
    "        def save_response_content(response, destination):\n",
    "            CHUNK_SIZE = 32768\n",
    "            with open(destination, \"wb\") as f:\n",
    "                for chunk in tqdm(response.iter_content(CHUNK_SIZE), desc='Image downloading'):\n",
    "                    if chunk:  # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "        session = requests.Session()\n",
    "        response = session.get(URL, params={'id': id}, stream=True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = {'id': id, 'confirm': token}\n",
    "            response = session.get(URL, params=params, stream=True)\n",
    "        save_response_content(response, destination)\n",
    "\n",
    "    file_id = '0B7IzDz-4yH_HMFdiSE44R1lselE'\n",
    "    path_to_tar_file = str(time.time()) + '.tar.gz'\n",
    "    download_file_from_google_drive(file_id, path_to_tar_file)\n",
    "    print('Extraction')\n",
    "    with tarfile.open(path_to_tar_file) as tar_ref:\n",
    "        tar_ref.extractall(os.path.dirname(img_folder))\n",
    "    os.remove(path_to_tar_file)\n",
    "# Also, copy our pre-processed annotations to the dataset folder.\n",
    "copyfile('../PyTorch-Multi-Label-Image-Classification-Image-Tagging/nus_wide/small_test.json', os.path.join(img_folder, 'small_test.json'))\n",
    "copyfile('../PyTorch-Multi-Label-Image-Classification-Image-Tagging/nus_wide/small_train.json', os.path.join(img_folder, 'small_train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want to represent our label names as vectors in order to use them as features further.\n",
    "# To do that we decided to use GloVe model (https://nlp.stanford.edu/projects/glove/).\n",
    "# Let's download GloVe model trained on a Wikipedia Text Corpus.\n",
    "glove_zip_name = 'glove.6B.zip'\n",
    "glove_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "# For our purposes, we use a model where each word is encoded by a vector of length 300\n",
    "target_model_name = 'glove.6B.300d.txt'\n",
    "if not os.path.exists(target_model_name):\n",
    "    with urllib.request.urlopen(glove_url) as dl_file:\n",
    "        with open(glove_zip_name, 'wb') as out_file:\n",
    "            out_file.write(dl_file.read())\n",
    "    # Extract zip archive.    \n",
    "    with zipfile.ZipFile(glove_zip_name) as zip_f:\n",
    "        zip_f.extract(target_model_name)\n",
    "    os.remove(glove_zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load GloVe model.\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(\"glove.6B.300d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GloVe embeddings for each label in our target label subset.\n",
    "small_labels = ['house', 'birds', 'sun', 'valley',\n",
    "               'nighttime', 'boats', 'mountain', 'tree', 'snow', 'beach', 'vehicle', 'rocks',\n",
    "               'reflection', 'sunset', 'road', 'flowers', 'ocean', 'lake', 'window', 'plants',\n",
    "               'buildings', 'grass', 'water', 'animal', 'person', 'clouds', 'sky']\n",
    "vectorized_labels = [embeddings_dict[label].tolist() for label in small_labels]\n",
    "\n",
    "# Save them for further use.\n",
    "word_2_vec_path = 'word_2_vec_glow_classes.json'\n",
    "with open(word_2_vec_path, 'w') as fp:\n",
    "    json.dump({\n",
    "        'vect_labels': vectorized_labels,\n",
    "    }, fp, indent=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how well GloVe represents label names from our dataset.\n",
    "# It would be hard to visualize vectors with 300 values, but luckly we have t-SNE for that.\n",
    "# This function builds a t-SNE model(https://www.learnopencv.com/t-sne-for-feature-visualization/) \n",
    "# for label embeddings and visualizes them.\n",
    "def tsne_plot(tokens, labels):\n",
    "    tsne_model = TSNE(perplexity=2, n_components=2, init='pca', n_iter=25000, random_state=2020, n_jobs=4)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(13, 13)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     size=15,\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can draw t-SNE visualization.\n",
    "tsne_plot(vectorized_labels, small_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dataset class for NUS-WIDE is the same as in our previous post. The only difference\n",
    "# is that we need to load vectorized representations of labels too.\n",
    "class NusDatasetGCN(Dataset):\n",
    "    def __init__(self, data_path, anno_path, transforms, w2v_path):\n",
    "        self.transforms = transforms\n",
    "        with open(anno_path) as fp:\n",
    "            json_data = json.load(fp)\n",
    "        samples = json_data['samples']\n",
    "        self.classes = json_data['labels']\n",
    "\n",
    "        self.imgs = []\n",
    "        self.annos = []\n",
    "        self.data_path = data_path\n",
    "        print('loading', anno_path)\n",
    "        for sample in samples:\n",
    "            self.imgs.append(sample['image_name'])\n",
    "            self.annos.append(sample['image_labels'])\n",
    "        for item_id in range(len(self.annos)):\n",
    "            item = self.annos[item_id]\n",
    "            vector = [cls in item for cls in self.classes]\n",
    "            self.annos[item_id] = np.array(vector, dtype=float)\n",
    "        # Load vectorized labels for GCN from json.    \n",
    "        with open(w2v_path) as fp:\n",
    "            self.gcn_inp = np.array(json.load(fp)['vect_labels'], dtype=float)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anno = self.annos[item]\n",
    "        img_path = os.path.join(self.data_path, self.imgs[item])\n",
    "        img = Image.open(img_path)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, anno, self.gcn_inp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the data we have. To do it we need to load the dataset without augmentations.\n",
    "dataset_val = NusDatasetGCN(img_folder, os.path.join(img_folder, 'small_test.json'), None, word_2_vec_path)\n",
    "dataset_train = NusDatasetGCN(img_folder, os.path.join(img_folder, 'small_train.json'), None, word_2_vec_path)\n",
    "\n",
    "# A simple function for visualization.\n",
    "def show_sample(img, binary_img_labels, _):\n",
    "    # Convert the binary labels back to the text representation.    \n",
    "    img_labels = np.array(dataset_val.classes)[np.argwhere(binary_img_labels > 0)[:, 0]]\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"{}\".format(', '.join(img_labels)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for sample_id in [13, 15, 22, 29, 57, 127]:\n",
    "    show_sample(*dataset_val[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label distribution for the entire dataset (train + test).\n",
    "samples = dataset_val.annos + dataset_train.annos\n",
    "samples = np.array(samples)\n",
    "with printoptions(precision=3, suppress=True):\n",
    "    class_counts = np.sum(samples, axis=0)\n",
    "    # Sort labels according to their frequency in the dataset.\n",
    "    sorted_ids = np.array([i[0] for i in sorted(enumerate(class_counts), key=lambda x: x[1])], dtype=int)\n",
    "    print('Label distribution (count, class name):', list(zip(class_counts[sorted_ids].astype(int), np.array(dataset_val.classes)[sorted_ids])))\n",
    "    plt.barh(range(len(dataset_val.classes)), width=class_counts[sorted_ids])\n",
    "    plt.yticks(range(len(dataset_val.classes)), np.array(dataset_val.classes)[sorted_ids])\n",
    "    plt.gca().margins(y=0)\n",
    "    plt.grid()\n",
    "    plt.title('Label distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To proceed with the training we first need to compute adjacency matrix.\n",
    "adj_matrix_path = 'adjacency_matrix.json'\n",
    "# Count all labels.\n",
    "nums = np.sum(np.array(dataset_train.annos), axis=0)\n",
    "label_len = len(small_labels)\n",
    "adj = np.zeros((label_len, label_len), dtype=int)\n",
    "# Now iterate over the whole training set and consider all pairs of labels in sample annotation.\n",
    "for sample in dataset_train.annos:\n",
    "    sample_idx = np.argwhere(sample > 0)[:, 0]\n",
    "    # We count all possible pairs that can be created from each sample's set of labels.\n",
    "    for i, j in itertools.combinations(sample_idx, 2):\n",
    "        adj[i, j] += 1\n",
    "        adj[j, i] += 1\n",
    "\n",
    "# Save it for further use.        \n",
    "with open(adj_matrix_path, 'w') as fp:\n",
    "    json.dump({\n",
    "        'nums': nums.tolist(),\n",
    "        'adj': adj.tolist()\n",
    "    }, fp, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use implementation of GCN from github repository: \n",
    "# https://github.com/Megvii-Nanjing/ML-GCN/blob/master/models.py#L7\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features), requires_grad=True)\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(1, 1, out_features), requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.matmul(input.float(), self.weight.float())\n",
    "        output = torch.matmul(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "# Create adjacency matrix from statistics.\n",
    "def gen_A(num_classes, t, p, adj_data):\n",
    "    adj = np.array(adj_data['adj']).astype(np.float32)\n",
    "    nums = np.array(adj_data['nums']).astype(np.float32)\n",
    "    nums = nums[:, np.newaxis]\n",
    "    adj = adj / nums\n",
    "    adj[adj < t] = 0\n",
    "    adj[adj >= t] = 1\n",
    "    adj = adj * p / (adj.sum(0, keepdims=True) + 1e-6)  \n",
    "    adj = adj + np.identity(num_classes, np.int)\n",
    "    return adj\n",
    "\n",
    "# Apply adjacency matrix re-normalization.\n",
    "def gen_adj(A):\n",
    "    D = torch.pow(A.sum(1).float(), -0.5)\n",
    "    D = torch.diag(D).type_as(A)\n",
    "    adj = torch.matmul(torch.matmul(A, D).t(), D)\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GCNResnext50(nn.Module):\n",
    "    def __init__(self, n_classes, adj_path, in_channel=300, t=0.1, p=0.25):\n",
    "        super().__init__()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        self.features = models.resnext50_32x4d(pretrained=True)\n",
    "        self.features.fc = nn.Identity()\n",
    "        self.num_classes = n_classes\n",
    "\n",
    "        self.gc1 = GraphConvolution(in_channel, 1024)\n",
    "        self.gc2 = GraphConvolution(1024, 2048)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        # Load data for adjacency matrix\n",
    "        with open(adj_path) as fp:\n",
    "            adj_data = json.load(fp)\n",
    "        # Compute adjacency matrix\n",
    "        adj = gen_A(n_classes, t, p, adj_data)\n",
    "        self.A = Parameter(torch.from_numpy(adj).float(), requires_grad=False)\n",
    "\n",
    "    def forward(self, imgs, inp):\n",
    "        # Get visual features from image\n",
    "        feature = self.features(imgs)\n",
    "        feature = feature.view(feature.size(0), -1)\n",
    "        \n",
    "        # Get graph features from graph\n",
    "        inp = inp[0].squeeze()\n",
    "        adj = gen_adj(self.A).detach()\n",
    "        x = self.gc1(inp, adj)\n",
    "        x = self.relu(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        \n",
    "        # We multiply the features from GСN and СNN in order to take into account \n",
    "        # the contribution to the prediction of classes from both the image and the graph.\n",
    "        x = x.transpose(0, 1)\n",
    "        x = torch.matmul(feature, x)\n",
    "        return self.sigm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    pred = np.array(pred > threshold, dtype=float)\n",
    "    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the training parameters.\n",
    "num_workers = 8 # Number of CPU processes for data preprocessing\n",
    "lr = 5e-6 # Learning rate\n",
    "batch_size = 32\n",
    "save_freq = 1 # Save checkpoint frequency (epochs)\n",
    "test_freq = 200 # Test model frequency (iterations)\n",
    "max_epoch_number = 35 # Number of epochs for training \n",
    "# Note: on the small subset of data overfitting happens after 30-35 epochs.\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# Save path for checkpoints.\n",
    "save_path = 'chekpoints/'\n",
    "# Save path for logs.\n",
    "logdir = 'logs/'\n",
    "\n",
    "# Run tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an auxiliary function for checkpoint saving.\n",
    "def checkpoint_save(model, save_path, epoch):\n",
    "    f = os.path.join(save_path, 'checkpoint-{:06d}.pth'.format(epoch))\n",
    "    if 'module' in dir(model):\n",
    "        torch.save(model.module.state_dict(), f)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f)\n",
    "    print('saved checkpoint:', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocessing.\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Train preprocessing.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(0.5, 1.5),\n",
    "                            shear=None, resample=False, \n",
    "                            fillcolor=tuple(np.array(np.array(mean) * 255).astype(int).tolist())),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataloaders for training.\n",
    "test_annotations = os.path.join(img_folder, 'small_test.json')\n",
    "train_annotations = os.path.join(img_folder, 'small_train.json')\n",
    "\n",
    "test_dataset = NusDatasetGCN(img_folder, test_annotations, val_transform, word_2_vec_path)\n",
    "train_dataset = NusDatasetGCN(img_folder, train_annotations, train_transform, word_2_vec_path)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True,\n",
    "                              drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "num_train_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
    "\n",
    "# Initialize the model.\n",
    "model = GCNResnext50(len(train_dataset.classes), adj_matrix_path)\n",
    "# Switch model to the training mode and move it to GPU.\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# If more than one GPU is available we can use both to speed up the training.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Loss function.\n",
    "criterion = nn.BCELoss()\n",
    "# Tensoboard logger.\n",
    "logger = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run training.\n",
    "epoch = 0\n",
    "iteration = 0\n",
    "while True:\n",
    "    batch_losses = []\n",
    "    for batch_number, (imgs, targets, gcn_input) in enumerate(train_dataloader):\n",
    "        imgs, targets, gcn_input = imgs.to(device), targets.to(device), gcn_input.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(imgs, gcn_input)\n",
    "        loss = criterion(model_result, targets.type(torch.float))\n",
    "\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 10.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        logger.add_scalar('train_loss', batch_loss_value, iteration)\n",
    "        batch_losses.append(batch_loss_value)\n",
    "        with torch.no_grad():\n",
    "            result = calculate_metrics(model_result.cpu().numpy(), targets.cpu().numpy())\n",
    "            for metric in result:\n",
    "                logger.add_scalar('train/' + metric, result[metric], iteration)\n",
    "\n",
    "        if iteration % test_freq == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                model_result = []\n",
    "                targets = []\n",
    "                for imgs, batch_targets, gcn_input in test_dataloader:\n",
    "                    gcn_input = gcn_input.to(device)\n",
    "                    imgs = imgs.to(device)\n",
    "                    model_batch_result = model(imgs, gcn_input)\n",
    "                    model_result.extend(model_batch_result.cpu().numpy())\n",
    "                    targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "            result = calculate_metrics(np.array(model_result), np.array(targets))\n",
    "            for metric in result:\n",
    "                logger.add_scalar('test/' + metric, result[metric], iteration)\n",
    "            print(\"epoch:{:2d} iter:{:3d} test: \"\n",
    "                  \"micro f1: {:.3f} \"\n",
    "                  \"macro f1: {:.3f} \"\n",
    "                  \"samples f1: {:.3f}\".format(epoch, iteration,\n",
    "                                              result['micro/f1'],\n",
    "                                              result['macro/f1'],\n",
    "                                              result['samples/f1']))\n",
    "\n",
    "            model.train()\n",
    "        iteration += 1\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    print(\"epoch:{:2d} iter:{:3d} train: loss:{:.3f}\".format(epoch, iteration, loss_value))\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_save(model, save_path, epoch)\n",
    "    epoch += 1\n",
    "    if max_epoch_number < epoch:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run inference on the test data.\n",
    "model.eval()\n",
    "for sample_id in [1, 2, 3, 4, 6]:\n",
    "    test_img, test_labels, gcn_input  = test_dataset[sample_id]\n",
    "    test_img_path = os.path.join(img_folder, test_dataset.imgs[sample_id])\n",
    "    with torch.no_grad():\n",
    "        raw_pred = model(test_img.unsqueeze(0).cuda(), torch.from_numpy(gcn_input).unsqueeze(0).cuda()).cpu().numpy()[0]\n",
    "        raw_pred = np.array(raw_pred > 0.5, dtype=float)\n",
    "\n",
    "    predicted_labels = np.array(dataset_val.classes)[np.argwhere(raw_pred > 0)[:, 0]]\n",
    "    if not len(predicted_labels):\n",
    "        predicted_labels = ['no predictions']\n",
    "    img_labels = np.array(dataset_val.classes)[np.argwhere(test_labels > 0)[:, 0]]\n",
    "    plt.imshow(Image.open(test_img_path))\n",
    "    plt.title(\"Predicted labels: {} \\nGT labels: {}\".format(', '.join(predicted_labels), ', '.join(img_labels)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog_venv",
   "language": "python",
   "name": "blog_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}