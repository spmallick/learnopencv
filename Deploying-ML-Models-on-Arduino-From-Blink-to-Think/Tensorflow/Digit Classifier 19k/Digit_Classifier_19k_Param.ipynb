{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d0e314-f706-4e5e-89eb-36bffed5082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984d3a4-517b-4c9d-beb1-c0bbffb13584",
   "metadata": {},
   "source": [
    "### Input 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52850b0-f882-4c32-b748-86c94d0c04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "# digits = load_digits()\n",
    "# X = digits.images / 16.0\n",
    "# y = digits.target.reshape(-1, 1)\n",
    "\n",
    "# # One-hot encode labels\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "# y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# # Flatten (8x8 → 64 features)\n",
    "# X = X.reshape(len(X), -1)\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y_encoded, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # Bigger model (~19k params)\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(64,)),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "#                     validation_split=0.1, verbose=1)\n",
    "\n",
    "# loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c54842-6e9b-4acd-b98f-85c237a1f8ac",
   "metadata": {},
   "source": [
    "### Input 28x28\n",
    "The following won't work as load digit data function only has 8x8 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ef3e63-750b-47ee-894c-5c40567d3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 784), found shape=(None, 64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m784\u001b[39m,)),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m ])\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     36\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 41\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegtbavgnt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 784), found shape=(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X = digits.images  # shape (n_samples, 28, 28)\n",
    "y = digits.target.reshape(-1, 1)\n",
    "\n",
    "# Normalize 0..1\n",
    "X = X / 16.0  # or 255.0 if your images are 0..255\n",
    "\n",
    "# Flatten 28x28 → 784 features\n",
    "X = X.reshape(len(X), -1)\n",
    "\n",
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Bigger model (~19k params)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "                    validation_split=0.1, verbose=1)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce35e5e-04c2-4824-a810-7eca966680b1",
   "metadata": {},
   "source": [
    "### Let's try loading with 28x28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33a7972-2b57-469e-bafe-f4a56ea823ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n",
      "Epoch 1/30\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2659 - accuracy: 0.9211 - val_loss: 0.1096 - val_accuracy: 0.9703\n",
      "Epoch 2/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1108 - accuracy: 0.9672 - val_loss: 0.0947 - val_accuracy: 0.9715\n",
      "Epoch 3/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0791 - accuracy: 0.9755 - val_loss: 0.1120 - val_accuracy: 0.9683\n",
      "Epoch 4/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0614 - accuracy: 0.9813 - val_loss: 0.0891 - val_accuracy: 0.9758\n",
      "Epoch 5/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.0978 - val_accuracy: 0.9713\n",
      "Epoch 6/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.1022 - val_accuracy: 0.9728\n",
      "Epoch 7/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0992 - val_accuracy: 0.9762\n",
      "Epoch 8/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.0941 - val_accuracy: 0.9780\n",
      "Epoch 9/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1055 - val_accuracy: 0.9750\n",
      "Epoch 10/30\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.1092 - val_accuracy: 0.9777\n",
      "Epoch 11/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.1094 - val_accuracy: 0.9763\n",
      "Epoch 12/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0887 - val_accuracy: 0.9795\n",
      "Epoch 13/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0992 - val_accuracy: 0.9790\n",
      "Epoch 14/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.1029 - val_accuracy: 0.9787\n",
      "Epoch 15/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1209 - val_accuracy: 0.9767\n",
      "Epoch 16/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1162 - val_accuracy: 0.9800\n",
      "Epoch 17/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1351 - val_accuracy: 0.9770\n",
      "Epoch 18/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1230 - val_accuracy: 0.9785\n",
      "Epoch 19/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.1210 - val_accuracy: 0.9765\n",
      "Epoch 20/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.1346 - val_accuracy: 0.9790\n",
      "Epoch 21/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.1256 - val_accuracy: 0.9792\n",
      "Epoch 22/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.1326 - val_accuracy: 0.9813\n",
      "Epoch 23/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.1242 - val_accuracy: 0.9795\n",
      "Epoch 24/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1187 - val_accuracy: 0.9795\n",
      "Epoch 25/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1275 - val_accuracy: 0.9805\n",
      "Epoch 26/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.1322 - val_accuracy: 0.9792\n",
      "Epoch 27/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1369 - val_accuracy: 0.9798\n",
      "Epoch 28/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1450 - val_accuracy: 0.9782\n",
      "Epoch 29/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1296 - val_accuracy: 0.9798\n",
      "Epoch 30/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1276 - val_accuracy: 0.9802\n",
      "Test Accuracy: 0.9805\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,146\n",
      "Trainable params: 111,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\kukil\\AppData\\Local\\Temp\\tmpjcpp_4d3\\assets\n",
      "INT8 TFLite model saved. Size: 114864 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# --- Load MNIST 28x28 dataset ---\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_test  = X_test.astype(np.float32) / 255.0\n",
    "\n",
    "# Flatten 28x28 → 784\n",
    "X_train_flat = X_train.reshape(-1, 784)\n",
    "X_test_flat  = X_test.reshape(-1, 784)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_onehot  = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# --- Build model (~19k params) ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train_flat, y_train_onehot,\n",
    "                    epochs=30, batch_size=32,\n",
    "                    validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test_flat, y_test_onehot, verbose=0)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- Convert to INT8 TFLite ---\n",
    "def representative_dataset():\n",
    "    for i in range(1000):  # first 1000 samples for calibration\n",
    "        yield [X_train_flat[i:i+1].astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save INT8 model\n",
    "with open(\"digits_model_28x28_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"INT8 TFLite model saved. Size:\", len(tflite_model), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3877f09-1a42-4a33-8f4a-4ff0ad36843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tensor Data Types ===\n",
      "serving_default_dense_4_input:0                              <class 'numpy.int8'>\n",
      "sequential_1/dense_7/BiasAdd/ReadVariableOp                  <class 'numpy.int32'>\n",
      "sequential_1/dense_7/MatMul                                  <class 'numpy.int8'>\n",
      "sequential_1/dense_6/BiasAdd/ReadVariableOp                  <class 'numpy.int32'>\n",
      "sequential_1/dense_6/MatMul                                  <class 'numpy.int8'>\n",
      "sequential_1/dense_5/BiasAdd/ReadVariableOp                  <class 'numpy.int32'>\n",
      "sequential_1/dense_5/MatMul                                  <class 'numpy.int8'>\n",
      "sequential_1/dense_4/BiasAdd/ReadVariableOp                  <class 'numpy.int32'>\n",
      "sequential_1/dense_4/MatMul                                  <class 'numpy.int8'>\n",
      "sequential_1/dense_4/MatMul;sequential_1/dense_4/Relu;sequential_1/dense_4/BiasAdd <class 'numpy.int8'>\n",
      "sequential_1/dense_5/MatMul;sequential_1/dense_5/Relu;sequential_1/dense_5/BiasAdd <class 'numpy.int8'>\n",
      "sequential_1/dense_6/MatMul;sequential_1/dense_6/Relu;sequential_1/dense_6/BiasAdd <class 'numpy.int8'>\n",
      "sequential_1/dense_7/MatMul;sequential_1/dense_7/BiasAdd     <class 'numpy.int8'>\n",
      "StatefulPartitionedCall:0                                    <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "# Check model layer wise data types\n",
    "interpreter = tf.lite.Interpreter(model_path=\"digits_model_28x28_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get all tensors\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "print(\"=== Tensor Data Types ===\")\n",
    "for t in tensor_details:\n",
    "    print(f\"{t['name']:<60} {t['dtype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "948339b9-fbb5-4d3d-be69-b91c38178ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float tensors: None ✅ Fully int8\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "interpreter = tf.lite.Interpreter(model_path=\"digits_model_28x28_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "details = interpreter.get_tensor_details()\n",
    "\n",
    "float_tensors = [d['name'] for d in details if d['dtype'] == np.float32]\n",
    "print(\"Float tensors:\", float_tensors if float_tensors else \"None ✅ Fully int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53ed079e-98cd-4b8a-b842-aca7499917e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_default\n",
      "\n",
      "=== Operator List ===\n",
      "FULLY_CONNECTED\n",
      "FULLY_CONNECTED\n",
      "FULLY_CONNECTED\n",
      "FULLY_CONNECTED\n",
      "SOFTMAX\n"
     ]
    }
   ],
   "source": [
    "for d in interpreter.get_signature_list():\n",
    "    print(d)\n",
    "\n",
    "print(\"\\n=== Operator List ===\")\n",
    "for op in interpreter._get_ops_details():\n",
    "    print(op[\"op_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820e7772-60fe-4005-a635-5577f3a614f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i digits_model_28x28_int8.tflite > digits_model_28x28_int8.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7637c-43a3-4e52-a061-531444cee38d",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc40d7cf-6481-4df3-8f37-18e5f6e6c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 143F-0886\n",
      "\n",
      " Directory of C:\\Users\\kukil\\Desktop\\OpenCV University\\tinyML\\Tensorflow\\Digit Classifier 19k\n",
      "\n",
      "10/05/2025  10:00 AM    <DIR>          .\n",
      "09/29/2025  08:35 AM    <DIR>          ..\n",
      "09/29/2025  09:55 AM    <DIR>          .ipynb_checkpoints\n",
      "10/05/2025  10:00 AM           283,830 digits_model_19k_int8.h\n",
      "10/05/2025  09:45 AM            22,688 digits_model_19k_int8.tflite\n",
      "10/05/2025  09:54 AM            16,839 Digit_Classifier_19k_Param.ipynb\n",
      "               3 File(s)        323,357 bytes\n",
      "               3 Dir(s)  322,934,611,968 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c71d57-14d0-40dc-bd7c-15a1169a1045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 5\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"digits_model_28x28_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test with one digit image\n",
    "img = Image.open(\"../../Dataset/MNIST_ORG/images/mnist_image_45.png\").convert(\"L\").resize((28, 28))\n",
    "# arr = np.array(img, dtype=np.float32)\n",
    "# arr = (arr / 255.0 * 255 - 128).astype(np.int8)  # same scaling as Arduino\n",
    "# arr = arr.reshape((1, 28, 28, 1))  # add batch/channel dim if needed\n",
    "\n",
    "arr = np.array(img, dtype=np.float32).flatten()   # 28*28 = 784\n",
    "# Scale to match int8 quantization used in Arduino\n",
    "arr = (arr / 255.0 * 255 - 128).astype(np.int8)\n",
    "arr = arr.reshape(1, 784)  # batch dimension only\n",
    "\n",
    "# interpreter.set_tensor(input_details[0]['index'], arr)\n",
    "# interpreter.invoke()\n",
    "# output = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(\"Predicted:\", np.argmax(output))\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], arr)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Predicted:\", np.argmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d0278-b3b4-4d3c-8888-304777a9953d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyML",
   "language": "python",
   "name": "tinyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
